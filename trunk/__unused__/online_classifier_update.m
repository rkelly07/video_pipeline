function res=online_classifier_update(res,descriptors,labels,unique_id,descriptor_representatives)
if(~isfield(res,'classifiers'))
    res.classifiers={};
    
    res.labels_map=containers.Map('KeyType','uint64','ValueType','uint64');
    res.label_cnt=0;
else
%     label_cnt=max(res.labels_map.keys);
end
if (~isfield(res,'train_params'))
    res.train_params=struct('learning_rate',1e-2,'net_topology',[20 5],'epochs',5);
end
uids=unique(unique_id);
Vs=zeros(size(descriptor_representatives,1),length(uids));
ls=zeros(1,length(uids));
features_vec=zeros(size(descriptor_representatives,1),length(uids));
descriptorst=descriptors';
% tic
for uid_=1:length(uids)
    uid=uids(uid_);
    %idx=find(unique_id==uid,1,'first');
%     class_id=labels(idx);
    class_id=labels(find(unique_id==uid,1,'first'));
    if (~res.labels_map.isKey(class_id))
        res.label_cnt=res.label_cnt+1;
        res.labels_map(class_id)=res.label_cnt;
        res.classifiers{res.label_cnt}=[];
        sequential_class_id=res.label_cnt;
    else
        sequential_class_id=res.labels_map(class_id);
    end
%     Vs(:,uid_)=features_vec;
    ls(uid_)=sequential_class_id;
    descriptors_i=descriptorst(unique_id==uid,:);
    features_vec(:,uid_)=create_features_vectorCPUGPU(descriptors_i,descriptor_representatives);
    
end
% toc
%     gpukernel = parallel.gpu.CUDAKernel('compute_VQ2.ptx','compute_VQ2.cu','computeVQ');
%     descriptor_representativesGPU=gpuArray(single(descriptor_representatives'));
%     descriptors_i=descriptors;
%     descriptors_iGPU=gpuArray(single(descriptors_i));
%     unique_idGPU=gpuArray(single(unique_id));
%     gpukernel.ThreadBlockSize=[128,1,1];
%     max_num_descs=200000;
% gpukernel.GridSize=[ceil(max_num_descs/gpukernel.ThreadBlockSize(1)),1];

%     features_vec=create_features_vector(descriptors_iGPU,descriptor_representativesGPU,unique_idGPU,length(uids),gpukernel);
Vs=features_vec;
seq_class_ids=unique(ls);
res.performances=[];
% classifiers_trained=[];
train_params=res.train_params;
classifiers={res.classifiers{seq_class_ids}};
for i=1:numel(seq_class_ids)
    idx=(ls==seq_class_ids(i));
        pn_ratio=3;
        max_p_ratio=5;
    p_num=sum(idx);
    n_num=sum(~idx);
    p_added=ceil(p_num*(1/pn_ratio/(p_num/n_num)-1));
    n_ratio=1;
    nidx=find(idx);
    if (p_added/p_num>max_p_ratio)
        p_added=p_num*max_p_ratio;
%         pn_ratio=(p_added+p_num)/n_num;
        n_ratio=max(15/sum(~idx),min(1,((p_num+p_added)*pn_ratio)/sum(~idx))); 
        
    end
    if (p_added>0)
        nidx=[nidx(:)',mod((1:p_added)-1,numel(idx))+1];
    end
    if (numel(ls)<100)
        idx2=~idx;
    else
        idx2=~idx&(rand(size(idx))<n_ratio);
    end
    if (isempty(classifiers{i}))
        Vp=Vs(:,nidx);
        Vn=Vs(:,idx2);
        [classifiers{i},stats]=construct_classifier(Vp,Vn,train_params);
    else
        Vp=Vs(:,nidx);
        Vn=Vs(:,idx2);
        [classifiers{i},stats]=update_classifier(classifiers{i},Vp,Vn,train_params);
    end
    performances(i)=stats.performance;
end
res.performances=performances;
res.classifiers(seq_class_ids)=classifiers;
% disp(['Average performance over all classifiers: ',num2str(mean(res.performances))]);
disp(['Classifiers trained: ',num2str(seq_class_ids)]);
end
function [net,stats]=update_classifier(net,Vp,Vn,train_params)
% inputs=[Vp,Vn];
inputs=net.userdata.preprocess_matrix*[Vp,Vn];

targets=[ones(size(Vp(1,:))),0*ones(size(Vn(1,:)))];
% net.trainParam.lr=train_params.learning_rate/numel(targets); % make it slower, in order to generalize over trained examples
net.trainParam.lr=train_params.learning_rate; % make it slower, in order to generalize over trained examples
stats.outputs = net(inputs);
stats.prev_performance = perform(net,targets,stats.outputs);%#ok
% [net,tr] = adapt(net,inputs,targets);
for i = 1:net.trainParam.epochs
[net,Y,E,Pf,Af,tr] = adapt(net,double(inputs),double(targets));
end
stats.outputs = net(inputs);
stats.errors = gsubtract(targets,stats.outputs);%#ok
stats.performance = perform(net,targets,stats.outputs);%#ok
stats.ratio=mean(targets);
end
function [net,stats]=construct_classifier(Vp,Vn,train_params)
[U,S,V]=svds([Vp,Vn],60);
% stats.preprocess=
preprocess_matrix=U';

inputs=preprocess_matrix*[Vp,Vn];
targets=[ones(size(Vp(1,:))),0*ones(size(Vn(1,:)))];
% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by NPRTOOL
% Created Sat Nov 23 17:25:01 EST 2013
%
% This script assumes these variables are defined:
%
%   V - input data.
%   l - target data.

% Create a Pattern Recognition Network

hiddenLayerSize = train_params.net_topology;
net = patternnet(hiddenLayerSize,'traingd');
net.userdata.preprocess_matrix=preprocess_matrix;
% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.inputs{1}.processFcns = {'removeconstantrows','mapminmax'};
net.outputs{2}.processFcns = {'removeconstantrows','mapminmax'};


% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% For help on training function 'trainlm' type: help trainlm
% For a list of all training functions type: help nntrain
% net.trainFcn = 'trainlm';  % Levenberg-Marquardt
% net.trainFcn = 'traingd';
% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean squared error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
% net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
%   'plotregression', 'plotfit'};
net.plotFcns ={};
net.trainParam.showWindow=false;
net.trainParam.epochs=train_params.epochs;
% net.trainParam.lr=train_params.learning_rate/numel(targets); % make it slower, in order to generalize over trained examples
net.trainParam.lr=train_params.learning_rate; % make it slower, in order to generalize over trained examples

% Train the Network
for initial_training_iter=1:15
    % double inputs are slower but single inputs tend to crash..
% [net,Y,E,Pf,Af,tr] = adapt(net,double(inputs),double(targets));
[net,tr] = train(net,double(inputs),double(targets));
end
% Test the Network
stats.outputs = net(inputs);
stats.errors = gsubtract(targets,stats.outputs);%#ok
stats.performance = perform(net,targets,stats.outputs);%#ok

% Recalculate Training, Validation and Test Performance
% trainTargets = targets .* tr.trainMask{1};
% valTargets = targets  .* tr.valMask{1};
% testTargets = targets  .* tr.testMask{1};
% trainPerformance = perform(net,trainTargets,stats.outputs);%#ok
% valPerformance = perform(net,valTargets,stats.outputs);%#ok
% testPerformance = perform(net,testTargets,stats.outputs);%#ok

% View the Network
% view(net)

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, plotconfusion(targets,outputs)
%figure, ploterrhist(errors)
end
function features_vec=create_features_vector(descriptors_i,descriptor_representatives,object_id,num_objects,k)
USE_GPU=true;
NumFeatureClusters=size(descriptor_representatives,2);
NumFeatureVectors=size(descriptors_i,2);
DimDesc=size(descriptor_representatives,1);
if (USE_GPU)
    
features_vec=gpuArray(single(zeros(num_objects,NumFeatureClusters)));
% for ii=1:2;
%float * descriptors, float *representatives, float *object_id,float * histogram,unsigned int num_representatives,unsigned int descriptor_dim,unsigned int num_descriptors,unsigned int num_objects
    [~,~,~,features_vec] = feval(k,descriptors_i,descriptor_representatives,object_id,features_vec,uint32(NumFeatureClusters),uint32(DimDesc),uint32(NumFeatureVectors),uint32(num_objects));
    features_vec=gather(features_vec);
% end
else
      pdists = pdist2(single(descriptors_i),single(descriptor_representatives));
      [~,knn_idx] = (min(pdists,[],2));
      features_vec = hist(knn_idx,NumFeatureClusters);
end
     % features_vec=features_vec/max(1,sum(features_vec));
end

function features_vec=create_features_vectorCPUGPU(descriptors_i,descriptor_representatives)
NumFeatureClusters=size(descriptor_representatives,1);
descriptors_i=gpuArray(single(descriptors_i));
descriptor_representatives=gpuArray(single(descriptor_representatives));
s1=sum(descriptors_i.^2,2);
s2=sum(descriptor_representatives.^2,2);
s1s2=bsxfun(@plus,s1(:),s2(:)');
pdists=bsxfun(@minus,s1s2,2*descriptors_i*descriptor_representatives');
%       pdists = pdist2(single(descriptors_i),single(descriptor_representatives));
      [~,knn_idx] = (min(pdists,[],2));
      features_vec = hist(knn_idx,NumFeatureClusters);
      features_vec=features_vec/max(1,sum(features_vec));
end
function features_vec=create_features_vectorCPU(descriptors_i,descriptor_representatives)
NumFeatureClusters=size(descriptor_representatives,1);

      pdists = pdist2(single(descriptors_i),single(descriptor_representatives));
      [~,knn_idx] = (min(pdists,[],2));
      features_vec = hist(knn_idx,NumFeatureClusters);
      features_vec=features_vec/max(1,sum(features_vec));
end